{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlQ2Uj5qdaHiwGS3rt202Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbenvenuto54/floreria-floreser/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFq0TrH5YwdP",
        "outputId": "23773016-a9bd-4679-8e11-393d45473200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://88edbbb733527b9a3b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://88edbbb733527b9a3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b1e63e5d370 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b1e63e5d370 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b1e63e5d370 [unset]> is bound to a different event loop\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 759, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2116, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1623, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3721726824.py\", line 166, in obtener_analisis_columnas\n",
            "    f\"Numéricas: {sum(np.issubdtype(tipos, np.number))}  |  \"\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: 'bool' object is not iterable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://88edbbb733527b9a3b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# ============================\n",
        "# 0. INSTALAR DEPENDENCIAS\n",
        "# ============================\n",
        "!pip install -q gradio pandas numpy seaborn matplotlib scipy xlsxwriter\n",
        "\n",
        "# ============================\n",
        "# 1. IMPORTS Y ESTADO GLOBAL\n",
        "# ============================\n",
        "import io\n",
        "import datetime as dt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from scipy import stats\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "STATE = {\n",
        "    \"df_original\": None,\n",
        "    \"df_trabajo\": None,\n",
        "    \"log\": []\n",
        "}\n",
        "\n",
        "# ============================\n",
        "# 2. LOG DE OPERACIONES\n",
        "# ============================\n",
        "def registrar_evento(etapa, descripcion, detalles=None):\n",
        "    timestamp = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    STATE[\"log\"].append({\n",
        "        \"timestamp\": timestamp,\n",
        "        \"etapa\": etapa,\n",
        "        \"descripcion\": descripcion,\n",
        "        \"detalles\": detalles or {}\n",
        "    })\n",
        "\n",
        "def generar_log_texto():\n",
        "    lineas = []\n",
        "    lineas.append(\"REPORTE AUTOMÁTICO DE PROCESAMIENTO DE DATOS\")\n",
        "    lineas.append(f\"Fecha y hora de generación: {dt.datetime.now()}\")\n",
        "    lineas.append(\"-\" * 60)\n",
        "\n",
        "    if STATE[\"df_original\"] is not None:\n",
        "        df0 = STATE[\"df_original\"]\n",
        "        lineas.append(\n",
        "            f\"Datos originales: {df0.shape[0]} filas, {df0.shape[1]} columnas.\"\n",
        "        )\n",
        "    if STATE[\"df_trabajo\"] is not None:\n",
        "        df = STATE[\"df_trabajo\"]\n",
        "        lineas.append(\n",
        "            f\"Datos finales: {df.shape[0]} filas, {df.shape[1]} columnas.\"\n",
        "        )\n",
        "\n",
        "    lineas.append(\"\")\n",
        "    lineas.append(\"Resumen de operaciones realizadas:\")\n",
        "    for ev in STATE[\"log\"]:\n",
        "        lineas.append(f\"[{ev['timestamp']}] {ev['etapa']}: {ev['descripcion']}\")\n",
        "\n",
        "    lineas.append(\"\")\n",
        "    lineas.append(\"Interpretación general:\")\n",
        "    lineas.append(\n",
        "        \"- Los datos fueron sometidos a procesos de limpieza \"\n",
        "        \"(tratamiento de nulos, normalización y outliers), \"\n",
        "        \"y se generaron estadísticas descriptivas y visualizaciones \"\n",
        "        \"para apoyar la toma de decisiones.\"\n",
        "    )\n",
        "    return \"\\n\".join(lineas)\n",
        "\n",
        "# ============================\n",
        "# 3. CARGA DE ARCHIVO\n",
        "# ============================\n",
        "def cargar_archivo_gradio(archivo, separador, tiene_header):\n",
        "    if archivo is None:\n",
        "        return (gr.update(value=None),\n",
        "                \"Error: Debes seleccionar un archivo.\",\n",
        "                \"Sin vista previa\")\n",
        "\n",
        "    nombre = archivo.name\n",
        "    extension = nombre.split(\".\")[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if extension == \"csv\":\n",
        "            sep = {\",\": \",\", \";\": \";\", \"tab\": \"\\t\", \"espacio\": \" \"}.get(\n",
        "                separador, \",\"\n",
        "            )\n",
        "            try:\n",
        "                df = pd.read_csv(\n",
        "                    archivo.name,\n",
        "                    sep=sep,\n",
        "                    header=0 if tiene_header else None,\n",
        "                    encoding=\"utf-8\"\n",
        "                )\n",
        "            except UnicodeDecodeError:\n",
        "                df = pd.read_csv(\n",
        "                    archivo.name,\n",
        "                    sep=sep,\n",
        "                    header=0 if tiene_header else None,\n",
        "                    encoding=\"latin1\"\n",
        "                )\n",
        "        elif extension in [\"xls\", \"xlsx\"]:\n",
        "            df = pd.read_excel(\n",
        "                archivo.name,\n",
        "                header=0 if tiene_header else None\n",
        "            )\n",
        "        else:\n",
        "            return (gr.update(value=None),\n",
        "                    \"Error: Solo se permiten archivos CSV o Excel.\",\n",
        "                    \"Sin vista previa\")\n",
        "    except Exception as e:\n",
        "        return (gr.update(value=None),\n",
        "                f\"Error al leer el archivo: {e}\",\n",
        "                \"Sin vista previa\")\n",
        "\n",
        "    # Validación flexible\n",
        "    tipos = df.dtypes\n",
        "    hay_numericas = tipos.apply(lambda t: np.issubdtype(t, np.number)).any()\n",
        "    hay_no_numericas = (~tipos.apply(lambda t: np.issubdtype(t, np.number))).any()\n",
        "\n",
        "    mensaje_extra = \"\"\n",
        "    if not (hay_numericas and hay_no_numericas):\n",
        "        mensaje_extra = (\n",
        "            \"\\n**Advertencia:** el archivo no contiene al menos una columna \"\n",
        "            \"numérica y una categórica. Algunas funciones podrían no estar \"\n",
        "            \"disponibles.\"\n",
        "        )\n",
        "\n",
        "    STATE[\"df_original\"] = df.copy()\n",
        "    STATE[\"df_trabajo\"] = df.copy()\n",
        "    STATE[\"log\"] = []\n",
        "\n",
        "    registrar_evento(\n",
        "        \"Carga de archivo\",\n",
        "        f\"Archivo '{nombre}' cargado correctamente.\",\n",
        "        {\"filas\": int(df.shape[0]), \"columnas\": int(df.shape[1])}\n",
        "    )\n",
        "\n",
        "    vista_previa = df.head(30)\n",
        "    mensaje = (\n",
        "        f\"Archivo '{nombre}' cargado correctamente. \"\n",
        "        f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}.\"\n",
        "        f\"{mensaje_extra}\"\n",
        "    )\n",
        "    return gr.update(value=vista_previa), mensaje, \"Vista previa generada.\"\n",
        "\n",
        "# ============================\n",
        "# 4. ANÁLISIS POR COLUMNAS\n",
        "# ============================\n",
        "def obtener_analisis_columnas():\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", None\n",
        "\n",
        "    tipos = df.dtypes\n",
        "    resumen = pd.DataFrame({\n",
        "        \"Columna\": tipos.index,\n",
        "        \"Tipo detectado\": tipos.astype(str).values,\n",
        "    })\n",
        "    sugerido = [\"Numérica\" if np.issubdtype(t, np.number)\n",
        "                else \"Categórica/Textual\" for t in tipos]\n",
        "    resumen[\"Tipo sugerido\"] = sugerido\n",
        "\n",
        "    texto = (\n",
        "        f\"Columnas totales: {df.shape[1]}  |  \"\n",
        "        f\"Numéricas: {sum(np.issubdtype(tipos, np.number))}  |  \"\n",
        "        f\"No numéricas: {sum(~np.issubdtype(tipos, np.number))}\"\n",
        "    )\n",
        "    return texto, resumen\n",
        "\n",
        "# ============================\n",
        "# 5. NULOS\n",
        "# ============================\n",
        "def analizar_nulos():\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", None\n",
        "\n",
        "    total = len(df)\n",
        "    nulos = df.isna().sum()\n",
        "    resumen = pd.DataFrame({\n",
        "        \"Columna\": nulos.index,\n",
        "        \"Nulos\": nulos.values,\n",
        "        \"Porcentaje\": (nulos.values / total * 100).round(2)\n",
        "    })\n",
        "    texto = f\"Se encontraron valores nulos en {sum(nulos > 0)} columnas.\"\n",
        "    return texto, resumen\n",
        "\n",
        "def procesar_nulos(metodo, columnas_texto):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", \"\"\n",
        "\n",
        "    columnas = [c.strip() for c in columnas_texto.split(\",\") if c.strip()]\n",
        "    if not columnas:\n",
        "        columnas = [c for c in df.columns if df[c].isna().any()]\n",
        "    if len(columnas) == 0:\n",
        "        return \"No hay columnas con valores nulos.\", \"\"\n",
        "\n",
        "    df_mod = df.copy()\n",
        "    filas_antes = len(df_mod)\n",
        "\n",
        "    for col in columnas:\n",
        "        if metodo == \"eliminar\":\n",
        "            df_mod = df_mod[df_mod[col].notna()]\n",
        "        else:\n",
        "            serie = df_mod[col]\n",
        "            if metodo == \"cero\":\n",
        "                valor = 0\n",
        "            elif metodo == \"promedio\":\n",
        "                valor = serie.mean()\n",
        "            elif metodo == \"mediana\":\n",
        "                valor = serie.median()\n",
        "            elif metodo == \"maximo\":\n",
        "                valor = serie.max()\n",
        "            elif metodo == \"minimo\":\n",
        "                valor = serie.min()\n",
        "            elif metodo == \"moda\":\n",
        "                valor = serie.mode().iloc[0] if not serie.mode().empty else 0\n",
        "            else:\n",
        "                valor = 0\n",
        "            df_mod[col] = serie.fillna(valor)\n",
        "\n",
        "    filas_despues = len(df_mod)\n",
        "    STATE[\"df_trabajo\"] = df_mod\n",
        "\n",
        "    registrar_evento(\n",
        "        \"Tratamiento de nulos\",\n",
        "        f\"Método '{metodo}' aplicado a columnas: {columnas}.\",\n",
        "        {\"filas_antes\": filas_antes, \"filas_despues\": filas_despues}\n",
        "    )\n",
        "\n",
        "    msg = (\n",
        "        f\"Tratamiento de nulos aplicado con método '{metodo}'. \"\n",
        "        f\"Filas antes: {filas_antes}, después: {filas_despues}.\"\n",
        "    )\n",
        "    return msg, f\"Operación completada sobre columnas: {', '.join(columnas)}\"\n",
        "\n",
        "# ============================\n",
        "# 6. NORMALIZACIÓN\n",
        "# ============================\n",
        "def normalizar_columnas(metodo, modo_salida, columnas_texto):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", None\n",
        "\n",
        "    columnas = [c.strip() for c in columnas_texto.split(\",\") if c.strip()]\n",
        "    if not columnas:\n",
        "        return \"Debes escribir al menos una columna numérica.\", None\n",
        "\n",
        "    df_mod = df.copy()\n",
        "    resumen = []\n",
        "\n",
        "    for col in columnas:\n",
        "        if col not in df_mod.columns:\n",
        "            continue\n",
        "        serie = df_mod[col].astype(float)\n",
        "        if metodo == \"minmax\":\n",
        "            minimo, maximo = serie.min(), serie.max()\n",
        "            if maximo - minimo == 0:\n",
        "                continue\n",
        "            nueva = (serie - minimo) / (maximo - minimo)\n",
        "            detalle = {\"min\": minimo, \"max\": maximo}\n",
        "        else:\n",
        "            media, std = serie.mean(), serie.std(ddof=0)\n",
        "            if std == 0:\n",
        "                continue\n",
        "            nueva = (serie - media) / std\n",
        "            detalle = {\"media\": media, \"std\": std}\n",
        "\n",
        "        nuevo_nombre = col if modo_salida == \"reemplazar\" else f\"{col}_norm\"\n",
        "        df_mod[nuevo_nombre] = nueva\n",
        "        resumen.append({\"Columna\": col, \"Método\": metodo, **detalle})\n",
        "\n",
        "    STATE[\"df_trabajo\"] = df_mod\n",
        "\n",
        "    registrar_evento(\n",
        "        \"Normalización\",\n",
        "        f\"Normalización '{metodo}' aplicada a columnas: {columnas}.\",\n",
        "        {}\n",
        "    )\n",
        "\n",
        "    resumen_df = pd.DataFrame(resumen) if resumen else None\n",
        "    return \"Normalización aplicada correctamente.\", resumen_df\n",
        "\n",
        "# ============================\n",
        "# 7. OUTLIERS\n",
        "# ============================\n",
        "def analizar_outliers():\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", None\n",
        "\n",
        "    numericas = df.select_dtypes(include=np.number)\n",
        "    if numericas.empty:\n",
        "        return \"No hay columnas numéricas.\", None\n",
        "\n",
        "    resumen = []\n",
        "    for col in numericas.columns:\n",
        "        serie = numericas[col].dropna()\n",
        "        if serie.empty:\n",
        "            continue\n",
        "        q1, q3 = np.percentile(serie, [25, 75])\n",
        "        iqr = q3 - q1\n",
        "        li, ls = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
        "        n_out = int(((serie < li) | (serie > ls)).sum())\n",
        "        resumen.append({\n",
        "            \"Columna\": col,\n",
        "            \"Q1\": q1,\n",
        "            \"Q3\": q3,\n",
        "            \"IQR\": iqr,\n",
        "            \"Límite inf\": li,\n",
        "            \"Límite sup\": ls,\n",
        "            \"Outliers\": n_out\n",
        "        })\n",
        "\n",
        "    if not resumen:\n",
        "        return \"No se encontraron outliers mediante IQR.\", None\n",
        "\n",
        "    return \"Análisis de outliers completado.\", pd.DataFrame(resumen)\n",
        "\n",
        "def procesar_outliers(metodo, columnas_texto):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", \"\"\n",
        "\n",
        "    columnas = [c.strip() for c in columnas_texto.split(\",\") if c.strip()]\n",
        "    if not columnas:\n",
        "        return \"Debes escribir al menos una columna.\", \"\"\n",
        "\n",
        "    df_mod = df.copy()\n",
        "    total_afectadas = 0\n",
        "\n",
        "    for col in columnas:\n",
        "        if col not in df_mod.columns:\n",
        "            continue\n",
        "        serie = df_mod[col].astype(float)\n",
        "        q1, q3 = np.percentile(serie.dropna(), [25, 75])\n",
        "        iqr = q3 - q1\n",
        "        li, ls = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
        "        mask = (serie < li) | (serie > ls)\n",
        "        afectados = int(mask.sum())\n",
        "        total_afectadas += afectados\n",
        "\n",
        "        if metodo == \"eliminar\":\n",
        "            df_mod = df_mod[~mask]\n",
        "        elif metodo == \"reemplazar_limite\":\n",
        "            serie[serie < li] = li\n",
        "            serie[serie > ls] = ls\n",
        "            df_mod[col] = serie\n",
        "        elif metodo == \"mediana\":\n",
        "            med = serie.median()\n",
        "            serie[mask] = med\n",
        "            df_mod[col] = serie\n",
        "        elif metodo == \"marcar\":\n",
        "            marca_col = f\"{col}_is_outlier\"\n",
        "            df_mod[marca_col] = mask.astype(int)\n",
        "\n",
        "    STATE[\"df_trabajo\"] = df_mod\n",
        "\n",
        "    registrar_evento(\n",
        "        \"Tratamiento de outliers (IQR)\",\n",
        "        f\"Método '{metodo}' aplicado.\",\n",
        "        {\"total_afectadas\": total_afectadas}\n",
        "    )\n",
        "    return (\n",
        "        f\"Tratamiento '{metodo}' aplicado. Registros afectados: {total_afectadas}.\",\n",
        "        \"\"\n",
        "    )\n",
        "\n",
        "# ============================\n",
        "# 8. ANÁLISIS ESTADÍSTICO Y GRÁFICOS\n",
        "# ============================\n",
        "def generar_analisis_estadistico(columnas_texto, x_reg, y_reg):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return \"No hay datos cargados.\", None, None, \"\", None\n",
        "\n",
        "    columnas = [c.strip() for c in columnas_texto.split(\",\") if c.strip()]\n",
        "    if not columnas:\n",
        "        return \"Debes escribir al menos una columna numérica.\", None, None, \"\", None\n",
        "\n",
        "    num_df = df[columnas].select_dtypes(include=np.number)\n",
        "    if num_df.empty:\n",
        "        return \"Las columnas seleccionadas no son numéricas.\", None, None, \"\", None\n",
        "\n",
        "    desc = num_df.describe().T\n",
        "    desc[\"Curtosis\"] = num_df.apply(stats.kurtosis, fisher=False)\n",
        "    desc[\"Asimetría\"] = num_df.apply(stats.skew)\n",
        "    desc = desc.round(4)\n",
        "\n",
        "    corr = num_df.corr()\n",
        "\n",
        "    interpretacion = []\n",
        "    umbral = 0.7\n",
        "    for i, c1 in enumerate(corr.columns):\n",
        "        for c2 in corr.columns[i+1:]:\n",
        "            valor = corr.loc[c1, c2]\n",
        "            if abs(valor) >= umbral:\n",
        "                interpretacion.append(\n",
        "                    f\"- Fuerte correlación entre {c1} y {c2} (r = {valor:.2f}).\"\n",
        "                )\n",
        "\n",
        "    for col in num_df.columns:\n",
        "        k = desc.loc[col, \"Curtosis\"]\n",
        "        s = desc.loc[col, \"Asimetría\"]\n",
        "        if k > 3:\n",
        "            interpretacion.append(\n",
        "                f\"- {col}: colas más pesadas que una normal (curtosis = {k:.2f}).\"\n",
        "            )\n",
        "        if abs(s) > 0.5:\n",
        "            lado = \"positiva\" if s > 0 else \"negativa\"\n",
        "            interpretacion.append(\n",
        "                f\"- {col}: asimetría {lado} (skew = {s:.2f}).\"\n",
        "            )\n",
        "\n",
        "    grafico = None\n",
        "    if x_reg and y_reg and x_reg in num_df.columns and y_reg in num_df.columns:\n",
        "        plt.figure(figsize=(5, 4))\n",
        "        sns.regplot(x=num_df[x_reg], y=num_df[y_reg], line_kws={\"color\": \"red\"})\n",
        "        plt.title(f\"Regresión lineal: {x_reg} vs {y_reg}\")\n",
        "        buf = io.BytesIO()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(buf, format=\"png\")\n",
        "        plt.close()\n",
        "        buf.seek(0)\n",
        "        grafico = buf\n",
        "        registrar_evento(\n",
        "            \"Análisis estadístico\",\n",
        "            f\"Descriptivos, correlaciones y regresión {x_reg}~{y_reg}.\"\n",
        "        )\n",
        "    else:\n",
        "        registrar_evento(\n",
        "            \"Análisis estadístico\",\n",
        "            \"Descriptivos y correlaciones sin regresión específica.\"\n",
        "        )\n",
        "\n",
        "    texto = \"\\n\".join(interpretacion) if interpretacion else \\\n",
        "        \"No se observaron correlaciones muy fuertes ni asimetrías significativas.\"\n",
        "    return \"Análisis generado correctamente.\", desc, corr, texto, grafico\n",
        "\n",
        "def generar_grafico(tipo, columnas_texto, col_categoria):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return None, \"No hay datos cargados.\"\n",
        "\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    if not num_cols:\n",
        "        return None, \"No hay columnas numéricas disponibles.\"\n",
        "\n",
        "    columnas = [c.strip() for c in columnas_texto.split(\",\") if c.strip()]\n",
        "\n",
        "    if tipo == \"Pairplot simple\":\n",
        "        if len(num_cols) < 2:\n",
        "            return None, \"Se requieren al menos 2 columnas numéricas.\"\n",
        "        subset = num_cols[:4]\n",
        "        g = sns.pairplot(df[subset].dropna())\n",
        "        buf = io.BytesIO()\n",
        "        g.fig.suptitle(\"Pairplot de variables numéricas\", y=1.02)\n",
        "        g.fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "        buf.seek(0)\n",
        "        plt.close(\"all\")\n",
        "        return buf, \"Pairplot generado.\"\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    if tipo == \"Histograma\":\n",
        "        if not columnas:\n",
        "            return None, \"Escribe al menos una columna numérica.\"\n",
        "        for col in columnas:\n",
        "            if col in num_cols:\n",
        "                sns.histplot(df[col].dropna(), kde=True, label=col, alpha=0.5)\n",
        "        plt.legend()\n",
        "        plt.title(\"Histogramas con KDE\")\n",
        "    elif tipo == \"Boxplot\":\n",
        "        if not columnas:\n",
        "            return None, \"Escribe al menos una columna numérica.\"\n",
        "        cols_validas = [c for c in columnas if c in num_cols]\n",
        "        sns.boxplot(data=df[cols_validas])\n",
        "        plt.title(\"Boxplots por columna\")\n",
        "    elif tipo == \"Distribución por categoría\":\n",
        "        if (not columnas) or (not col_categoria):\n",
        "            return None, \"Escribe una numérica y una categórica.\"\n",
        "        num_col = columnas[0]\n",
        "        if num_col not in num_cols or col_categoria not in df.columns:\n",
        "            return None, \"Las columnas seleccionadas no son válidas.\"\n",
        "        sns.boxplot(x=df[col_categoria], y=df[num_col])\n",
        "        plt.title(f\"Distribución de {num_col} por {col_categoria}\")\n",
        "    elif tipo == \"Heatmap de correlación\":\n",
        "        corr = df[num_cols].corr()\n",
        "        sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)\n",
        "        plt.title(\"Matriz de correlación\")\n",
        "    else:\n",
        "        return None, \"Tipo de gráfico no soportado.\"\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(buf, format=\"png\")\n",
        "    buf.seek(0)\n",
        "    plt.close()\n",
        "    return buf, f\"Gráfico '{tipo}' generado correctamente.\"\n",
        "\n",
        "# ============================\n",
        "# 9. EXPORTACIÓN\n",
        "# ============================\n",
        "def exportar_datos(formato):\n",
        "    df = STATE[\"df_trabajo\"]\n",
        "    if df is None:\n",
        "        return None, None, \"No hay datos procesados para exportar.\"\n",
        "\n",
        "    if formato == \"csv\":\n",
        "        buffer = io.StringIO()\n",
        "        df.to_csv(buffer, index=False)\n",
        "        datos_bytes = buffer.getvalue().encode(\"utf-8\")\n",
        "        nombre_datos = \"datos_procesados.csv\"\n",
        "    else:\n",
        "        buffer = io.BytesIO()\n",
        "        with pd.ExcelWriter(buffer, engine=\"xlsxwriter\") as writer:\n",
        "            df.to_excel(writer, index=False, sheet_name=\"Datos\")\n",
        "        datos_bytes = buffer.getvalue()\n",
        "        nombre_datos = \"datos_procesados.xlsx\"\n",
        "\n",
        "    log_text = generar_log_texto()\n",
        "    log_bytes = log_text.encode(\"utf-8\")\n",
        "    nombre_log = \"reporte_log.txt\"\n",
        "\n",
        "    registrar_evento(\"Exportación\",\n",
        "                     f\"Datos exportados en formato {formato}.\")\n",
        "\n",
        "    return (datos_bytes, nombre_datos), (log_bytes, nombre_log), \\\n",
        "        \"Datos y log generados correctamente.\"\n",
        "\n",
        "# ============================\n",
        "# 10. INTERFAZ GRADIO\n",
        "# ============================\n",
        "tema = gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"blue\")\n",
        "\n",
        "def _map_sep(sep_label):\n",
        "    if \"Punto y coma\" in sep_label:\n",
        "        return \";\"\n",
        "    if \"Tabulación\" in sep_label:\n",
        "        return \"tab\"\n",
        "    if \"Espacio\" in sep_label:\n",
        "        return \"espacio\"\n",
        "    return \",\"\n",
        "\n",
        "with gr.Blocks(\n",
        "    title=\"Aplicación Interactiva de Minería de Datos\",\n",
        "    theme=tema,\n",
        "    css=\"\"\"\n",
        "    .gradio-container { max-width: 1200px !important; margin: auto !important; }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "    gr.Markdown(\n",
        "        \"## Aplicación Interactiva de Minería de Datos\\n\"\n",
        "        \"Cargá, limpiá, analizá y exportá tus datos con un flujo guiado.\"\n",
        "    )\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # TAB 1\n",
        "        with gr.TabItem(\"Subir Archivo\"):\n",
        "            gr.Markdown(\n",
        "                \"### Cargar archivo de datos (CSV / Excel)\\n\"\n",
        "                \"Sube un archivo para comenzar.\"\n",
        "            )\n",
        "            with gr.Row():\n",
        "                separador = gr.Radio(\n",
        "                    [\"Coma (,)\", \"Punto y coma (;)\", \"Tabulación (tab)\", \"Espacio\"],\n",
        "                    value=\"Coma (,)\",\n",
        "                    label=\"Separador del CSV\"\n",
        "                )\n",
        "                tiene_header = gr.Checkbox(\n",
        "                    value=True,\n",
        "                    label=\"La primera fila contiene encabezados\"\n",
        "                )\n",
        "            archivo = gr.File(\n",
        "                label=\"Archivo Excel o CSV\",\n",
        "                file_types=[\".csv\", \".xlsx\", \".xls\"]\n",
        "            )\n",
        "            boton_cargar = gr.Button(\"Cargar y previsualizar\", variant=\"primary\")\n",
        "            vista_previa = gr.Dataframe(\n",
        "                label=\"Vista previa (primeras 30 filas)\",\n",
        "                interactive=False\n",
        "            )\n",
        "            mensaje_carga = gr.Markdown()\n",
        "            detalle_carga = gr.Markdown()\n",
        "\n",
        "            boton_cargar.click(\n",
        "                fn=lambda f, s, h: cargar_archivo_gradio(f, _map_sep(s), h),\n",
        "                inputs=[archivo, separador, tiene_header],\n",
        "                outputs=[vista_previa, mensaje_carga, detalle_carga]\n",
        "            )\n",
        "\n",
        "        # TAB 2\n",
        "        with gr.TabItem(\"Análisis por Columna\"):\n",
        "            gr.Markdown(\"### Análisis por columna\")\n",
        "            boton_analizar_cols = gr.Button(\"Analizar columnas\", variant=\"primary\")\n",
        "            resumen_cols_txt = gr.Markdown()\n",
        "            resumen_cols_df = gr.Dataframe(\n",
        "                label=\"Resumen de columnas\", interactive=False\n",
        "            )\n",
        "            boton_analizar_cols.click(\n",
        "                fn=obtener_analisis_columnas,\n",
        "                inputs=None,\n",
        "                outputs=[resumen_cols_txt, resumen_cols_df]\n",
        "            )\n",
        "\n",
        "        # TAB 3\n",
        "        with gr.TabItem(\"Datos Nulos\"):\n",
        "            gr.Markdown(\"### Análisis y tratamiento de valores nulos\")\n",
        "            boton_analizar_nulos = gr.Button(\n",
        "                \"Analizar valores nulos\", variant=\"secondary\"\n",
        "            )\n",
        "            resumen_nulos_txt = gr.Markdown()\n",
        "            resumen_nulos_df = gr.Dataframe(\n",
        "                label=\"Resumen de nulos por columna\", interactive=False\n",
        "            )\n",
        "            boton_analizar_nulos.click(\n",
        "                fn=analizar_nulos,\n",
        "                inputs=None,\n",
        "                outputs=[resumen_nulos_txt, resumen_nulos_df]\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"#### Tratamiento de valores nulos\")\n",
        "            metodo_nulos = gr.Radio(\n",
        "                choices=[\n",
        "                    (\"Reemplazar con cero\", \"cero\"),\n",
        "                    (\"Reemplazar con promedio\", \"promedio\"),\n",
        "                    (\"Reemplazar con mediana\", \"mediana\"),\n",
        "                    (\"Reemplazar con máximo\", \"maximo\"),\n",
        "                    (\"Reemplazar con mínimo\", \"minimo\"),\n",
        "                    (\"Reemplazar con moda\", \"moda\"),\n",
        "                    (\"Eliminar registros con nulos\", \"eliminar\")\n",
        "                ],\n",
        "                value=\"promedio\",\n",
        "                label=\"Método de tratamiento\"\n",
        "            )\n",
        "            columnas_nulos = gr.Textbox(\n",
        "                label=\"Columnas a tratar (coma separada, vacío = todas)\",\n",
        "                placeholder=\"ej: edad, ingreso_mensual\"\n",
        "            )\n",
        "            boton_procesar_nulos = gr.Button(\n",
        "                \"Procesar valores nulos\", variant=\"primary\"\n",
        "            )\n",
        "            mensaje_nulos = gr.Markdown()\n",
        "            detalle_nulos = gr.Markdown()\n",
        "            boton_procesar_nulos.click(\n",
        "                fn=procesar_nulos,\n",
        "                inputs=[metodo_nulos, columnas_nulos],\n",
        "                outputs=[mensaje_nulos, detalle_nulos]\n",
        "            )\n",
        "\n",
        "        # TAB 4\n",
        "        with gr.TabItem(\"Normalización\"):\n",
        "            gr.Markdown(\"### Normalización de datos numéricos\")\n",
        "            metodo_norm = gr.Radio(\n",
        "                [(\"Min-Max\", \"minmax\"), (\"Z-Score\", \"zscore\")],\n",
        "                value=\"minmax\",\n",
        "                label=\"Método de normalización\"\n",
        "            )\n",
        "            modo_salida = gr.Radio(\n",
        "                [(\"Reemplazar columnas existentes\", \"reemplazar\"),\n",
        "                 (\"Crear nuevas columnas\", \"nuevas\")],\n",
        "                value=\"nuevas\",\n",
        "                label=\"Tratamiento de columnas\"\n",
        "            )\n",
        "            columnas_norm = gr.Textbox(\n",
        "                label=\"Columnas numéricas a normalizar (coma separada)\",\n",
        "                placeholder=\"ej: ingreso_mensual, edad\"\n",
        "            )\n",
        "            boton_norm = gr.Button(\"Normalizar columnas\", variant=\"primary\")\n",
        "            mensaje_norm = gr.Markdown()\n",
        "            resumen_norm_df = gr.Dataframe(\n",
        "                label=\"Resumen de normalización\", interactive=False\n",
        "            )\n",
        "            boton_norm.click(\n",
        "                fn=normalizar_columnas,\n",
        "                inputs=[metodo_norm, modo_salida, columnas_norm],\n",
        "                outputs=[mensaje_norm, resumen_norm_df]\n",
        "            )\n",
        "\n",
        "        # TAB 5\n",
        "        with gr.TabItem(\"Outliers\"):\n",
        "            gr.Markdown(\"### Análisis de valores atípicos (Outliers)\")\n",
        "            boton_analizar_out = gr.Button(\n",
        "                \"Analizar outliers (IQR)\", variant=\"secondary\"\n",
        "            )\n",
        "            resumen_out_txt = gr.Markdown()\n",
        "            resumen_out_df = gr.Dataframe(\n",
        "                label=\"Resumen de outliers por columna\", interactive=False\n",
        "            )\n",
        "            boton_analizar_out.click(\n",
        "                fn=analizar_outliers,\n",
        "                inputs=None,\n",
        "                outputs=[resumen_out_txt, resumen_out_df]\n",
        "            )\n",
        "\n",
        "            metodo_out = gr.Radio(\n",
        "                [\n",
        "                    (\"Eliminar registros con outliers\", \"eliminar\"),\n",
        "                    (\"Reemplazar con límite inferior/superior\", \"reemplazar_limite\"),\n",
        "                    (\"Reemplazar con mediana\", \"mediana\"),\n",
        "                    (\"Marcar con columna indicador\", \"marcar\")\n",
        "                ],\n",
        "                value=\"eliminar\",\n",
        "                label=\"Método para tratar outliers\"\n",
        "            )\n",
        "            columnas_out = gr.Textbox(\n",
        "                label=\"Columnas a tratar (coma separada)\",\n",
        "                placeholder=\"ej: ingreso_mensual\"\n",
        "            )\n",
        "            boton_proc_out = gr.Button(\"Procesar outliers\", variant=\"primary\")\n",
        "            mensaje_out = gr.Markdown()\n",
        "            detalle_out = gr.Markdown()\n",
        "            boton_proc_out.click(\n",
        "                fn=procesar_outliers,\n",
        "                inputs=[metodo_out, columnas_out],\n",
        "                outputs=[mensaje_out, detalle_out]\n",
        "            )\n",
        "\n",
        "        # TAB 6\n",
        "        with gr.TabItem(\"Análisis Descriptivo\"):\n",
        "            gr.Markdown(\"### Análisis estadístico y visualizaciones\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    columnas_analisis = gr.Textbox(\n",
        "                        label=\"Columnas numéricas a analizar (coma separada)\",\n",
        "                        placeholder=\"ej: edad, ingreso_mensual, satisfaccion\"\n",
        "                    )\n",
        "                    x_reg = gr.Textbox(label=\"Variable X para regresión (opcional)\")\n",
        "                    y_reg = gr.Textbox(label=\"Variable Y para regresión (opcional)\")\n",
        "                    boton_analisis = gr.Button(\n",
        "                        \"Generar análisis numérico\", variant=\"primary\"\n",
        "                    )\n",
        "                    mensaje_analisis = gr.Markdown()\n",
        "                    desc_df = gr.Dataframe(\n",
        "                        label=\"Estadísticos descriptivos extendidos\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "                    corr_df = gr.Dataframe(\n",
        "                        label=\"Matriz de correlación\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "                    interpretacion_txt = gr.Markdown()\n",
        "                    grafico_reg = gr.Image(label=\"Regresión lineal (opcional)\",\n",
        "                                           interactive=False)\n",
        "                    boton_analisis.click(\n",
        "                        fn=generar_analisis_estadistico,\n",
        "                        inputs=[columnas_analisis, x_reg, y_reg],\n",
        "                        outputs=[mensaje_analisis, desc_df, corr_df,\n",
        "                                 interpretacion_txt, grafico_reg]\n",
        "                    )\n",
        "                with gr.Column():\n",
        "                    tipo_grafico = gr.Radio(\n",
        "                        [\"Histograma\", \"Boxplot\", \"Distribución por categoría\",\n",
        "                         \"Heatmap de correlación\", \"Pairplot simple\"],\n",
        "                        value=\"Histograma\",\n",
        "                        label=\"Tipo de gráfico\"\n",
        "                    )\n",
        "                    columnas_graf = gr.Textbox(\n",
        "                        label=\"Columnas numéricas (coma separada)\",\n",
        "                        placeholder=\"ej: edad, ingreso_mensual\"\n",
        "                    )\n",
        "                    columna_cat = gr.Textbox(\n",
        "                        label=\"Columna categórica (para 'Distribución por categoría')\",\n",
        "                        placeholder=\"ej: segmento\"\n",
        "                    )\n",
        "                    boton_grafico = gr.Button(\n",
        "                        \"Generar gráfico\", variant=\"secondary\"\n",
        "                    )\n",
        "                    grafico_generado = gr.Image(\n",
        "                        label=\"Gráfico generado\", interactive=False\n",
        "                    )\n",
        "                    mensaje_grafico = gr.Markdown()\n",
        "                    boton_grafico.click(\n",
        "                        fn=generar_grafico,\n",
        "                        inputs=[tipo_grafico, columnas_graf, columna_cat],\n",
        "                        outputs=[grafico_generado, mensaje_grafico]\n",
        "                    )\n",
        "\n",
        "        # TAB 7\n",
        "        with gr.TabItem(\"Descargar Archivo\"):\n",
        "            gr.Markdown(\"### Exportar datos procesados y reporte de log\")\n",
        "            formato_export = gr.Radio(\n",
        "                [(\"CSV\", \"csv\"), (\"Excel\", \"excel\")],\n",
        "                value=\"csv\",\n",
        "                label=\"Formato de descarga\"\n",
        "            )\n",
        "            boton_export = gr.Button(\n",
        "                \"Generar archivos para descargar\", variant=\"primary\"\n",
        "            )\n",
        "            archivo_salida = gr.File(label=\"Datos procesados\")\n",
        "            archivo_log = gr.File(label=\"Registro de Log\")\n",
        "            mensaje_export = gr.Markdown()\n",
        "\n",
        "            def _exportar(formato):\n",
        "                datos, log, msj = exportar_datos(formato)\n",
        "                datos_file = None\n",
        "                log_file = None\n",
        "                if datos is not None:\n",
        "                    datos_file = gr.update(\n",
        "                        value=io.BytesIO(datos[0]), label=datos[1]\n",
        "                    )\n",
        "                if log is not None:\n",
        "                    log_file = gr.update(\n",
        "                        value=io.BytesIO(log[0]), label=log[1]\n",
        "                    )\n",
        "                return datos_file, log_file, msj\n",
        "\n",
        "            boton_export.click(\n",
        "                fn=_exportar,\n",
        "                inputs=[formato_export],\n",
        "                outputs=[archivo_salida, archivo_log, mensaje_export]\n",
        "            )\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ]
}